{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af00150-2a6a-46fd-8a4d-ddd73b151b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.0-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\jmomn\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\jmomn\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-3.0.0-py3-none-win_amd64.whl (150.0 MB)\n",
      "   ---------------------------------------- 0.0/150.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 4.5/150.0 MB 24.5 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 12.6/150.0 MB 31.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 25.2/150.0 MB 40.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 28.6/150.0 MB 34.9 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 40.6/150.0 MB 40.4 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 53.2/150.0 MB 44.0 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 60.6/150.0 MB 42.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 67.9/150.0 MB 42.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 74.4/150.0 MB 40.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 80.5/150.0 MB 39.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 86.0/150.0 MB 38.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 92.8/150.0 MB 37.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 100.1/150.0 MB 37.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 108.0/150.0 MB 37.5 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 115.6/150.0 MB 37.5 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 122.4/150.0 MB 37.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 129.2/150.0 MB 36.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 135.8/150.0 MB 36.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 141.6/150.0 MB 36.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  148.1/150.0 MB 35.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  149.9/150.0 MB 35.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 150.0/150.0 MB 34.2 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe7a448-189a-443d-acc8-2ca7be8d48f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmomn\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [10:10:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Disaster Classification: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmomn\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [10:10:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target (Disaster/Non-disaster) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       780\n",
      "           1       0.90      0.79      0.84       642\n",
      "\n",
      "    accuracy                           0.86      1422\n",
      "   macro avg       0.87      0.86      0.86      1422\n",
      "weighted avg       0.87      0.86      0.86      1422\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmomn\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [10:11:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Disaster Type Classification: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmomn\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [10:11:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Disaster Type Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.88        55\n",
      "           1       0.98      0.89      0.93       182\n",
      "           2       0.82      0.96      0.88        24\n",
      "           3       0.88      0.95      0.91       517\n",
      "           4       0.99      1.00      1.00       201\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.95      0.88      0.91       198\n",
      "           7       0.94      0.92      0.93       236\n",
      "\n",
      "    accuracy                           0.92      1422\n",
      "   macro avg       0.81      0.80      0.81      1422\n",
      "weighted avg       0.92      0.92      0.92      1422\n",
      "\n",
      "\n",
      "Predictions for sample texts:\n",
      "\n",
      "Text: A huge forest fire has broken out in California\n",
      "Prediction: Disaster\n",
      "Disaster Type: fire\n",
      "\n",
      "Text: I love the way the sun sets in the evening\n",
      "Prediction: Not a disaster\n",
      "Disaster Type: medical\n",
      "\n",
      "Text: Earthquake magnitude 7.2 hits Japan coast\n",
      "Prediction: Disaster\n",
      "Disaster Type: earthquake\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load and preprocess the data\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('train.csv')\n",
    "df = df.dropna(subset=['text', 'target', 'disaster_type'])\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Prepare features (X) and targets (y)\n",
    "X = df['processed_text']\n",
    "\n",
    "# Encode target and disaster_type\n",
    "le_disaster = LabelEncoder()\n",
    "disaster_types_encoded = le_disaster.fit_transform(df['disaster_type'])\n",
    "df['target'] = df['target'].astype(int)\n",
    "y_disaster = df['target']\n",
    "y_type = disaster_types_encoded\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train_disaster, y_test_disaster = train_test_split(X, y_disaster, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train_type, y_test_type = train_test_split(X, y_type, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Define parameter grid for GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Grid search for disaster classification\n",
    "xgb_disaster = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "grid_search_disaster = GridSearchCV(xgb_disaster, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_disaster.fit(X_train_vectorized, y_train_disaster)\n",
    "print(\"Best Parameters for Disaster Classification:\", grid_search_disaster.best_params_)\n",
    "\n",
    "# Train best model\n",
    "best_xgb_disaster = grid_search_disaster.best_estimator_\n",
    "best_xgb_disaster.fit(X_train_vectorized, y_train_disaster)\n",
    "predictions_disaster = best_xgb_disaster.predict(X_test_vectorized)\n",
    "print(\"\\nTarget (Disaster/Non-disaster) Classification Report:\")\n",
    "print(classification_report(y_test_disaster, predictions_disaster))\n",
    "\n",
    "# Grid search for disaster type classification\n",
    "xgb_type = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "grid_search_type = GridSearchCV(xgb_type, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_type.fit(X_train_vectorized, y_train_type)\n",
    "print(\"Best Parameters for Disaster Type Classification:\", grid_search_type.best_params_)\n",
    "\n",
    "# Train best model\n",
    "best_xgb_type = grid_search_type.best_estimator_\n",
    "best_xgb_type.fit(X_train_vectorized, y_train_type)\n",
    "predictions_type = best_xgb_type.predict(X_test_vectorized)\n",
    "print(\"\\nDisaster Type Classification Report:\")\n",
    "print(classification_report(y_test_type, predictions_type))\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_disaster(text):\n",
    "    try:\n",
    "        processed = preprocess_text(text)\n",
    "        vectorized = vectorizer.transform([processed])\n",
    "        is_disaster = \"Disaster\" if best_xgb_disaster.predict(vectorized)[0] == 1 else \"Not a disaster\"\n",
    "        disaster_type = le_disaster.inverse_transform([best_xgb_type.predict(vectorized)[0]])[0]\n",
    "        return is_disaster, disaster_type\n",
    "    except Exception as e:\n",
    "        print(f\"Error in prediction: {e}\")\n",
    "        return \"Unknown\", \"Unknown\"\n",
    "\n",
    "# Example usage\n",
    "sample_texts = [\n",
    "    \"A huge forest fire has broken out in California\",\n",
    "    \"I love the way the sun sets in the evening\",\n",
    "    \"Earthquake magnitude 7.2 hits Japan coast\"\n",
    "]\n",
    "\n",
    "print(\"\\nPredictions for sample texts:\")\n",
    "for text in sample_texts:\n",
    "    is_disaster, disaster_type = predict_disaster(text)\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Prediction: {is_disaster}\")\n",
    "    print(f\"Disaster Type: {disaster_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e9418-f75d-4957-9925-c8c5dc0b0bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
